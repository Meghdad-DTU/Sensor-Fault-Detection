{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/paladin/Downloads/Sensor-Fault-Detection'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PredictionConfig:\n",
    "    root_dir: Path   \n",
    "    drift_report_file: Path\n",
    "    best_model_dir: Path  \n",
    "    valid_train_file: Path  \n",
    "    schema_numerical_columns: list\n",
    "    target_column: str\n",
    "    pvalue_threshold: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sensorFaultDetection.constants import *\n",
    "from sensorFaultDetection.utils import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath=CONFIG_FILE_PATH,\n",
    "                 secret_filepath=SECRET_FILE_PATH,\n",
    "                 schema_filepath=SCHEMA_FILE_PATH,\n",
    "                 params_filepath=PARAMS_FILE_PATH\n",
    "                 ):\n",
    "       \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.secret = read_yaml(secret_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_prediction_config(self) -> PredictionConfig: \n",
    "        config = self.config.prediction\n",
    "        \n",
    "        create_directories([config.ROOT_DIR])      \n",
    "\n",
    "        prediction_config = PredictionConfig(\n",
    "            root_dir = config.ROOT_DIR,\n",
    "            drift_report_file= config.DRIFT_REPORT_FILE,\n",
    "            best_model_dir = self.config.model_evaluation.ROOT_DIR,\n",
    "            valid_train_file= self.config.data_validation.VALID_TRAIN_FILE,\n",
    "            schema_numerical_columns= self.schema.numerical_columns,\n",
    "            target_column= self.params.TARGET_COLUMN,\n",
    "            pvalue_threshold= self.params.PVALUE_THRESHOLD\n",
    "        )\n",
    "        \n",
    "        return prediction_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from sensorFaultDetection.logger import logging\n",
    "from scipy.stats import ks_2samp\n",
    "from sensorFaultDetection.exception import CustomException\n",
    "from sensorFaultDetection.utils import load_pickle, write_yaml_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetValueMapping:\n",
    "    def __init__(self):\n",
    "        self.neg: int = 0\n",
    "        self.pos: int = 1\n",
    "\n",
    "    def to_dict(self):\n",
    "        return self.__dict__\n",
    "\n",
    "    def reverse_mapping(self):\n",
    "        mapping_response = self.to_dict()\n",
    "\n",
    "        return dict(zip(mapping_response.values(), mapping_response.keys()))\n",
    "\n",
    "\n",
    "class Prediction:\n",
    "    def __init__(self, filename: Path, config: PredictionConfig):\n",
    "        self.config = config\n",
    "        self.filename = filename\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_dir_empty(path: Path) -> bool:       \n",
    "        if os.path.exists(path) and not os.path.isfile(path):  \n",
    "            # Checking if the directory is empty or not\n",
    "            if not os.listdir(path):\n",
    "                #Empty directory\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        else:\n",
    "            #The path is either for a file or not valid\"\n",
    "            return False\n",
    "    \n",
    "    @staticmethod\n",
    "    def only_directory_names(dir_path: Path) -> str:\n",
    "        # How to list ONLY directories in Python\n",
    "        dir_names = []\n",
    "        items = os.listdir(dir_path)        \n",
    "        for item in items:\n",
    "            if os.path.isdir(os.path.join(dir_path, item)):\n",
    "                dir_names.append(item)\n",
    "        return dir_names\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_required_column_exist(required_input: list, df:pd.DataFrame) -> bool:\n",
    "        try:\n",
    "            column_present= True\n",
    "            missing__columns = []\n",
    "            for column in df.columns:\n",
    "                if column  not in required_input:\n",
    "                    column_present= False\n",
    "                    missing__columns.append(column)\n",
    "            \n",
    "            if not column_present:\n",
    "                logging.info(f\"Missing columns for prediction: {missing__columns:}\")        \n",
    "            \n",
    "            return column_present\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    @staticmethod\n",
    "    def detect_dataset_drift(base_dataframe: pd.DataFrame, current_datafrme: pd.DataFrame, threshold: float):\n",
    "        try:\n",
    "            status = True\n",
    "            report ={}\n",
    "            for column in base_dataframe.columns:\n",
    "                df1 = base_dataframe[column]\n",
    "                df2 = current_datafrme[column]\n",
    "                is_same_dist = ks_2samp(df1, df2)\n",
    "                if is_same_dist.pvalue >= threshold:\n",
    "                    is_found = False\n",
    "                else:\n",
    "                    is_found = True\n",
    "                    status = False\n",
    "                \n",
    "                report.update({column:{\n",
    "                    'p_value': float(is_same_dist.pvalue),\n",
    "                    'drift_status': is_found\n",
    "                            }})\n",
    "            return status, report\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)        \n",
    "\n",
    "    def get_best_model_path(self) -> Path:\n",
    "        try:\n",
    "            if self.is_dir_empty(self.config.best_model_dir) is False:                              \n",
    "                raise Exception(\"WARNING: there is no trained model available for prediction!\")      \n",
    "                   \n",
    "            dir_name = self.only_directory_names(self.config.best_model_dir)[-1]                      \n",
    "            best_model_path = os.path.join(self.config.best_model_dir, dir_name, 'model.pkl')                     \n",
    "            if not os.path.exists(best_model_path):                              \n",
    "                raise Exception(\"WARNING:  there is no trained model available for prediction!\")             \n",
    "            \n",
    "            return best_model_path\n",
    "        \n",
    "        except Exception as e:\n",
    "            CustomException(e, sys)\n",
    "    \n",
    "    def initiate_prediction(self):\n",
    "        try:\n",
    "            best_model_path = self.get_best_model_path()            \n",
    "            model = load_pickle(best_model_path)\n",
    "            df = pd.read_csv(self.filename)\n",
    "            input_variables = self.config.schema_numerical_columns  \n",
    "\n",
    "            if self.config.target_column in df.columns:\n",
    "                df.drop(self.config.target_column, axis=1, inplace=True)           \n",
    "            \n",
    "            if not self.is_required_column_exist(input_variables, df):\n",
    "                raise Exception('WARNING: missing column issue exists, check the input data for the prediction!')\n",
    "            \n",
    "            df = df[input_variables]                                   \n",
    "            logging.info(\"Reading data is completed!\")\n",
    "\n",
    "            status, drift_report = self.detect_dataset_drift(self.config.valid_train_file, df, self.config.pvalue_threshold)\n",
    "            write_yaml_file(path= self.config.drift_report_file, content= drift_report, replace= True)\n",
    "            \n",
    "            if status:   \n",
    "                logging.info('NO data drift issue!') \n",
    "            else:\n",
    "                 logging.info(f'WARNING: We faced data drift issue, check {self.config.drift_report_file}')\n",
    "\n",
    "            y_pred = model.predict(df)\n",
    "            df['predicted_class']= y_pred\n",
    "            df['predicted_class'].replace(TargetValueMapping().reverse_mapping(), inplace=True)\n",
    "            logging.info(\"Implementation of the trained model on the new data is completed!\")            \n",
    "            return df\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sensorFaultDetection.exception import CustomException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'artifacts/data_validation/valid/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prediction_config = config.get_prediction_config()\n",
    "    prediction = Prediction(filename=file_path, config=prediction_config)\n",
    "    df = prediction.initiate_prediction()    \n",
    "except Exception as e:\n",
    "    CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/paladin/Downloads/Sensor-Fault-Detection/research/06_prediction.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/paladin/Downloads/Sensor-Fault-Detection/research/06_prediction.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
